@article{norelli2022explanatory,
 abstract = {At the crossroads of Program Synthesis and Meta-Learning, we introduce Explanatory Learning as the task of automatically discovering the symbolic explanation (PS) that enables few-shot sensible predictions on a novel environment given experience on other environments (M-L). Differently from PS, the program (explanation) interpreter in EL is not given and should be learned from a limited collection of associations explanation-observations. Unlike M-L, EL does not prescribe any adaptation at test time, seeking generalization in the broad meanings attributed to symbols by the learned interpreter. To exemplify the challenges of EL, we present the Odeen benchmark, which can also serve the PS and M-L paradigms. Finally, we introduce Critical Rationalist Networks, a deep learning approach to EL aligned with the Popperian view of knowledge acquisition. CRNs express several desired properties by construction; they are truly explainable, can adjust their processing at test-time for harder inferences, and can offer strong confidence guarantees on their predictions. Using Odeen as a testbed, we show how CRNs outperform empiricist end-to-end approaches of similar size and architecture (Transformers) in discovering explanations for unseen environments.},
 author = {Norelli, Antonio and Mariani, Giorgio and Moschella, Luca and Santilli, Andrea and Parascandolo, Giambattista and Melzi, Simone and Rodol√†, Emanuele},
 journal = {arXiv preprint arXiv:2201.10222},
 title = {Explanatory learning: Beyond empiricism in neural networks},
 year = {2022}
}

